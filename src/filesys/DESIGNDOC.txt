+-------------------------+
                     |            OS           |
                     | PROJECT 4: FILE SYSTEMS |
                     |     DESIGN DOCUMENT     |
                     +-------------------------+


---- GROUP ----


>> Fill in the names and email addresses of your group members.


Paras Gupta <gupta.paras@iitgn.ac.in> 19110128
Shubh Lavti <sunil.sl@iitgn.ac.in> 19110090
Tarun Sharma <sharma_tarun@iitgn.ac.in> 19110140


---- PRELIMINARIES ----


>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.


>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.


                     INDEXED AND EXTENSIBLE FILES
                     ============================


---- DATA STRUCTURES ----


>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


The following data structure was added in inode.c to store indirect inode block pointers:


struct iblock_struct{
        uint32_t block[128]; --> stores the indirect block pointers
};


The following two members were added to two data structures - struct inode_disk and struct inode defined respectively - in inode.h in order to implement indexed and extensible files as given in PintOS documentation:


block_sector_t block[115]; --> pointer to store direct inode blocks
uint32_t inode_data[10]; --> stores information like indexing information and directory implementation.


>> A2: What is the maximum size of a file supported by your inode
>> structure?  Show your work.


Maximum size of the file is given by the unit size of each block used times the number of blocks used.


Let us look at the number of blocks we used:-
* Single indirect  blocks - 128
* Double indirect blocks - 128x128
* Direct blocks - 113
Therefore, we used a total of 16625 blocks. Also, the size of each block in the above case was 512.


So, maximum size of the file = 16625(total blocks) x 512(size of each block)
                                   = 8512000 bytes
                                   = 8.12 MB


---- SYNCHRONIZATION ----


>> A3: Explain how your code avoids a race if two processes attempt to
>> extend a file at the same time.


If in case two processes attempt to extend a file at the same time, the file would be extended by the process that had run first. After this, the next process wouldn’t face any issue because by that time an extended file would already be there and there would be no need to extend it again.


>> A4: Suppose processes A and B both have file F open, both
>> positioned at end-of-file.  If A reads and B writes F at the same
>> time, A may read all, part, or none of what B writes.  However, A
>> may not read data other than what B writes, e.g. if B writes
>> nonzero data, A is not allowed to see all zeros.  Explain how your
>> code avoids this race.


Considering the above situation, two situations are possible from the implementation of our code. It can happen that B writes into F first or A could read F first as well. Thus,         at a given time only one process can open the file F as all these events are mutually exclusive.


>> A5: Explain how your synchronization design provides "fairness".
>> File access is "fair" if readers cannot indefinitely block writers
>> or vice versa.  That is, many processes reading from a file cannot
>> prevent forever another process from writing the file, and many
>> processes writing to a file cannot prevent another process forever
>> from reading the file.


This function has not been implemented in our code.


---- RATIONALE ----


>> A6: Is your inode structure a multilevel index?  If so, why did you
>> choose this particular combination of direct, indirect, and doubly
>> indirect blocks?  If not, why did you choose an alternative inode
>> structure, and what advantages and disadvantages does your
>> structure have, compared to a multilevel index?


Yes, our inode structure uses multilevel index structure. We chose the above combination of blocks because the main purpose for doing so is to increase the maximum file size supported by the system. 
The only disadvantage that we noticed in the above structure was that it increases the number of disc operations required to locate the required block.


                            SUBDIRECTORIES
                            ==============


---- DATA STRUCTURES ----


>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


The following member was added to struct thread defined in thread.h:


        struct dir *working_dir; --> directory pointer that stores the current working directory for 
       the thread




---- ALGORITHMS ----


>> B2: Describe your code for traversing a user-specified path.  How
>> do traversals of absolute and relative paths differ?


In our implementation, the initial character is tested to see if it is a '/' or a '.' to determine if the provided route is absolute or relative. If there is a '/', it is assumed that the specified path is absolute, and we begin from the root directory. In the other instance, after we've confirmed that the path is relative, we begin at the current working directory.


Now, consider parsing through the path. The idea of a parsed token can be understood from the below arguments/cases which is required to traverse through a valid user-specified path:-


* If we want to look for a directory/file:
if (strstr(curr_token, ".") == NULL || (strlen(file_name) != 1 && strlen(file_name) != 2))
* To check the current directory:
if (strcmp(curr_token, '.') == 0)
* To get to the previous directory:
if (strcmp('..', curr_token) == 0)




---- SYNCHRONIZATION ----


>> B4: How do you prevent races on directory entries?  For example,
>> only one of two simultaneous attempts to remove a single file
>> should succeed, as should only one of two simultaneous attempts to
>> create a file with the same name, and so on.


File_lock is used to prevent races on directory entries. This ensures that at a given time, only a single process can perform any operation. This successfully avoids any possibilities of races.


>> B5: Does your implementation allow a directory to be removed if it
>> is open by a process or if it is in use as a process's current
>> working directory?  If so, what happens to that process's future
>> file system operations?  If not, how do you prevent it?


No, our code implementation does not allow any directory to be removed if it is open by a  process or if it is in use as a process's current working directory. It is implemented such that it guarantees that a directory is not deleted if it is not empty or if it is being used by another process.


---- RATIONALE ----


>> B6: Explain why you chose to represent the current directory of a
>> process the way you did.


We chose a dir type pointer to encounter the problem of representing the current directory of a process. In comparison to having an inode, etc., a simple pointer seems like the simplest method to implement.


                             BUFFER CACHE
                             ============


---- DATA STRUCTURES ----


>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.


The data structure - struct buffer_struct - was created in filesys.h to help in implementing the buffer cache:


struct buffer_struct{
        uint8_t content[BLOCK_SECTOR_SIZE]; --> stores th buffer content
        struct list_elem buffer_listelem; --> list element for buffer_list
bool dirty; --> flag to determine if any data was written to the buffer
        bool access; --> flag to determine if the buffer was accessed
uint32_t sector; --> Stores the sector information where buffer was stored on the disk
};


We also defined a buffer lock in the same file as follows:
struct lock buffer_lock; --> buffer lock for synchronization
        


---- ALGORITHMS ----


>> C2: Describe how your cache replacement algorithm chooses a cache
>> block to evict.


The defined buffer_evict() function evicts a dirty block that has not been accessed. This is achieved by setting the access and dirty flag for any cache block. Whenever access is made to a cache block, its access flag is set to true and in the case of any modifications to the data present inside the cache, the dirt flag is set to true.


>> C3: Describe your implementation of write-behind.


At system halt, when the file system module shuts, we iterate through the cache and write the dirty entries back to the disk.


>> C4: Describe your implementation of read-ahead.


Upon retrieving a cache from a block, a new thread is created which accesses the next data block sector from inode and puts it in the cache. Cache lock would be active to prevent any race conditions from other processes trying to modify the cache.


---- SYNCHRONIZATION ----


>> C5: When one process is actively reading or writing data in a
>> buffer cache block, how are other processes prevented from evicting
>> that block?


We use a buffer_lock to prevent other processes from evicting the active block. The lock is acquired or released when required. The read, write, and evict operations are thus synchronized.


>> C6: During the eviction of a block from the cache, how are other
>> processes prevented from attempting to access the block?


We use a buffer_lock to prevent multiple processes from accessing the evicting block from the cache simultaneously. The lock is acquired or released when required. 


---- RATIONALE ----


>> C7: Describe a file workload likely to benefit from buffer caching,
>> and workloads likely to benefit from read-ahead and write-behind.


When reading small files, buffer caching is likely to be beneficial.
When reading an entire file, read-ahead is likely to benefit.
When writing small bytes to file, write-behind is likely to help.


                           SURVEY QUESTIONS
                           ================


Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.


>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?


>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?


>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?


>> Do you have any suggestions for the TAs to more effectively assist
>> students in future quarters?


>> Any other comments?